openapi: 3.0.3
info:
  title: Darkwebsearch - Crawler API
  version: "1.0.0"
  description: API for crawling dark web sites and managing crawler settings.
  license:
    name: MIT
    url: https://opensource.org/licenses/MIT

servers:
  - url: "/"
    description: Relative server URL â€” replace with the real base URL when deployed

paths:
  /crawl/start:
    post:
      summary: Start a new crawl job
      operationId: startCrawl
      security:
        - bearerAuth: []
      requestBody:
        content:
          application/json:
            schema:
              type: object
              required: [url]
              properties:
                url:
                  type: string
                  description: Starting URL for the crawl
                  example: "http://example.onion"
                depth:
                  type: integer
                  description: Maximum crawl depth
                  default: 3
                  example: 3
                follow_links:
                  type: boolean
                  description: Whether to follow links found on pages
                  default: true
                respect_robots:
                  type: boolean
                  description: Whether to respect robots.txt
                  default: true
                rate_limit:
                  type: integer
                  description: Rate limit in requests per second
                  default: 1
                  example: 1
      responses:
        "200":
          description: Crawl job started successfully
          content:
            application/json:
              schema:
                type: object
                properties:
                  job_id:
                    type: string
                    description: Unique identifier for the crawl job
                  status:
                    type: string
                    enum: [queued, running]
                  message:
                    type: string
        "400":
          description: Invalid request
          content:
            application/problem+json:
              schema:
                $ref: '#/components/schemas/Error'
        "503":
          description: Service unavailable
          content:
            application/problem+json:
              schema:
                $ref: '#/components/schemas/Error'

  /crawl/status/{job_id}:
    get:
      summary: Get status of a crawl job
      operationId: getCrawlStatus
      security:
        - bearerAuth: []
      parameters:
        - name: job_id
          in: path
          required: true
          schema:
            type: string
          description: Unique identifier for the crawl job
      responses:
        "200":
          description: Crawl job status retrieved successfully
          content:
            application/json:
              schema:
                type: object
                properties:
                  job_id:
                    type: string
                  status:
                    type: string
                    enum: [queued, running, completed, failed]
                  progress:
                    type: object
                    properties:
                      pages_crawled:
                        type: integer
                      links_found:
                        type: integer
                      errors:
                        type: integer
                  started_at:
                    type: string
                    format: date-time
                  completed_at:
                    type: string
                    format: date-time
                    nullable: true
        "404":
          description: Job not found
          content:
            application/problem+json:
              schema:
                $ref: '#/components/schemas/Error'

  /crawl/stop/{job_id}:
    post:
      summary: Stop a running crawl job
      operationId: stopCrawl
      security:
        - bearerAuth: []
      parameters:
        - name: job_id
          in: path
          required: true
          schema:
            type: string
          description: Unique identifier for the crawl job
      responses:
        "200":
          description: Crawl job stopped successfully
          content:
            application/json:
              schema:
                type: object
                properties:
                  job_id:
                    type: string
                  status:
                    type: string
                    enum: [stopped]
                  message:
                    type: string
        "404":
          description: Job not found
          content:
            application/problem+json:
              schema:
                $ref: '#/components/schemas/Error'

  /settings:
    get:
      summary: Get crawler settings
      operationId: getSettings
      security:
        - bearerAuth: []
      responses:
        "200":
          description: Crawler settings retrieved successfully
          content:
            application/json:
              schema:
                $ref: '#/components/schemas/CrawlerSettings'

    put:
      summary: Update crawler settings
      operationId: updateSettings
      security:
        - bearerAuth: []
      requestBody:
        content:
          application/json:
            schema:
              $ref: '#/components/schemas/CrawlerSettings'
      responses:
        "200":
          description: Settings updated successfully
          content:
            application/json:
              schema:
                type: object
                properties:
                  message:
                    type: string
                  settings:
                    $ref: '#/components/schemas/CrawlerSettings'
        "400":
          description: Invalid settings
          content:
            application/problem+json:
              schema:
                $ref: '#/components/schemas/Error'

  /health:
    get:
      summary: Health check endpoint
      operationId: healthCheck
      responses:
        "200":
          description: Service is healthy
          content:
            application/json:
              schema:
                type: object
                properties:
                  status:
                    type: string
                    enum: [healthy]
                  timestamp:
                    type: string
                    format: date-time

components:
  securitySchemes:
    bearerAuth:
      type: http
      scheme: bearer
      bearerFormat: JWT

  schemas:
    CrawlerSettings:
      type: object
      properties:
        default_depth:
          type: integer
          description: Default crawl depth
          default: 3
        default_rate_limit:
          type: integer
          description: Default rate limit in requests per second
          default: 1
        max_concurrent_jobs:
          type: integer
          description: Maximum number of concurrent crawl jobs
          default: 5
        respect_robots_txt:
          type: boolean
          description: Whether to respect robots.txt by default
          default: true
        user_agent:
          type: string
          description: User agent string to use for requests
          default: "DarkwebsearchCrawler/1.0"
        timeout:
          type: integer
          description: Request timeout in seconds
          default: 30
        enable_javascript:
          type: boolean
          description: Whether to enable JavaScript rendering with Selenium
          default: true
        multithreading:
          type: boolean
          description: Enable multithreading for crawling
          default: false

    Error:
      type: object
      properties:
        type:
          type: string
        title:
          type: string
        status:
          type: integer
        detail:
          type: string
